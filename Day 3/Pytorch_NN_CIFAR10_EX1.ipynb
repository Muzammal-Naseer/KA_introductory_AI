{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BCpQaqwoH2Pk"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HBuuF9MJKjoe"
      },
      "outputs": [],
      "source": [
        "# Download the required libraries (needed when running outside colab where the environment doesn't come pre-loaded with libraries)\n",
        "\n",
        "%pip install torch\n",
        "%pip install torchvision\n",
        "%pip install matplotlib\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gtV7omCIKq0K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms.functional import to_tensor, to_pil_image, resize\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBNjc2JpLGIa"
      },
      "source": [
        "#Contents:\n",
        "\n",
        "1. We'll make a classifier for CIFAR10 dataset in pytorch using a NN architecture\n",
        "\n",
        "About CIFAR10:\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "![CIFAR-10 image](https://production-media.paperswithcode.com/datasets/4fdf2b82-2bc3-4f97-ba51-400322b228b1.png)\n",
        "\n",
        "\n",
        "You need to know:\n",
        "\n",
        "1. **torch** (for impelementation)\n",
        "2. a little bit of **matplotlib** (for visualization)\n",
        "\n",
        "\n",
        "Good to have knowledge of:\n",
        "\n",
        "1. torch dataset and dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw5z1ZSoLlh1"
      },
      "source": [
        "# Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlJwrK5ZLDeV",
        "outputId": "c90306df-22ea-4724-c50b-b4ce997620f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "dataset_root = 'data/'\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root=dataset_root, train=True, download=True, transform=data_transform)\n",
        "val_dataset = CIFAR10(root=dataset_root, train=False, download=True, transform=data_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ugrf0DMF2N",
        "outputId": "b724452b-f6fc-47cb-cac2-d6adebe52f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train_dataset is 50000\n",
            "Length of val_dataset is 10000\n"
          ]
        }
      ],
      "source": [
        "print('Length of train_dataset is', len(train_dataset))\n",
        "print('Length of val_dataset is'  , len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Oj4XUGKBQmwH"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # no need to shuffle validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cBvsQtwejyV"
      },
      "source": [
        "## Implement the Network"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}