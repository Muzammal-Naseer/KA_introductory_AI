{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qWb17ZPBAWvP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCpQaqwoH2Pk"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download the required libraries (needed when running outside colab where the environment doesn't come pre-loaded with libraries)\n",
        "\n",
        "%pip install torch\n",
        "%pip install torchvision\n",
        "%pip install matplotlib\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "HBuuF9MJKjoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms.functional import to_tensor, to_pil_image, resize\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gtV7omCIKq0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sign Langauge Problem:\n",
        "\n",
        "## Intution: The AI is so powrful and important because of its various applications on most if not all the different fields. As a result, we want to help in solving the issue of not understanding sign languages.\n",
        "\n",
        "## - This notebook contains a detailed implementaiton of a NN uisng Pytorch.\n",
        "\n",
        "### 1. Data set Details:\n",
        "\n",
        "- The provided data set is ArASL (Arabic Alphabets Sign Language Dataset). It is as its name says, an arabic sighn langauge for Arabic alphabet. It has a total of 54049 images and their corrssponding labels.\n",
        "\n",
        "### 2. Size of data:\n",
        "- Length of train_dataset is 43239,\n",
        "- Length of val_dataset is 10810\n",
        "\n",
        "### 3. Labels representations:\n",
        "- Each sample has a label, which can be one of the 32 classes.\n",
        "It consist of 32 classes for the alphabet.\n",
        "- The classes values are integers from 0 up to 31.\n",
        "\n",
        "\n",
        "### 4. The mapping details:\n",
        "\n",
        "- Each number represents a charcter. You can see the dictionary in the variable \"mapping\".\n",
        "\n",
        "<br/>\n",
        "-- You can see the mapping in the following:\n",
        "\n",
        "0: 'seen', 1: 'zay', 2: 'aleff', 3: 'dal', 4: 'ta', 5: 'yaa', 6: 'fa', 7: 'ya', 8: 'khaa', 9: 'nun', 10: 'ha', 11: 'toot', 12: 'taa', 13: 'ra', 14: 'kaaf', 15: 'jeem', 16: 'laam', 17: 'la', 18: 'dhad', 19: 'dha', 20: 'waw', 21: 'meem', 22: 'al', 23: 'sheen', 24: 'haa', 25: 'thaa', 26: 'saad', 27: 'ghain', 28: 'ain', 29: 'thal', 30: 'gaaf', 31: 'bb'\n",
        "\n",
        "### 5. Refrence:\n",
        "Latif, G., Mohammad, N., Alghazo, J., AlKhalaf, R., & AlKhalaf, R. (2019). ARASL: Arabic Alphabets Sign Language Dataset. *Data in Brief*, 23, 103777. https://doi.org/10.1016/j.dib.2019.103777"
      ],
      "metadata": {
        "id": "JBNjc2JpLGIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the dataset\n",
        "\n",
        "### Run the following cells to download the MNIST dataset."
      ],
      "metadata": {
        "id": "Gw5z1ZSoLlh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://data.mendeley.com/public-files/datasets/y7pckrw6z2/files/1efa0d6b-4d7f-4f58-9584-08f0488279ee/file_downloaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqQxPwbp7TfV",
        "outputId": "1b94cb83-74d8-4aad-e88a-f6ce023370bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://data.mendeley.com/public-files/datasets/y7pckrw6z2/files/1efa0d6b-4d7f-4f58-9584-08f0488279ee/file_downloaded\n",
            "To: /content/file_downloaded\n",
            "100% 66.2M/66.2M [00:06<00:00, 10.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def delete_folder(folder_path):\n",
        "    try:\n",
        "        # Get the list of files and subdirectories in the folder\n",
        "        for item in os.listdir(folder_path):\n",
        "            item_path = os.path.join(folder_path, item)\n",
        "\n",
        "            # If it's a file, delete it\n",
        "            if os.path.isfile(item_path):\n",
        "                os.remove(item_path)\n",
        "            # If it's a directory, recursively call delete_folder\n",
        "            elif os.path.isdir(item_path):\n",
        "                delete_folder(item_path)\n",
        "\n",
        "        # Remove the empty folder\n",
        "        os.rmdir(folder_path)\n",
        "        print(f\"Folder '{folder_path}' and its contents deleted successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Folder '{folder_path}' not found.\")\n",
        "    except PermissionError:\n",
        "        print(f\"Permission error: Unable to delete folder '{folder_path}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "delete_folder('ArASL_Database_54K_Final')\n",
        "\n",
        "!unzip file_downloaded\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "yfnx8Ebf7pTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Just run these two cells. You are not supposed to explore them."
      ],
      "metadata": {
        "id": "qWb17ZPBAWvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def rename_folders_and_create_mapping(folder_path):\n",
        "    # Get the list of folders in the specified path\n",
        "    folders = [folder for folder in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, folder))]\n",
        "\n",
        "    # Create a mapping from original folder names to numbers\n",
        "    folder_mapping = {folder: i for i, folder in enumerate(folders)}\n",
        "\n",
        "    # Rename the folders in-place and store the original names in the mapping\n",
        "    for original_folder, number in folder_mapping.items():\n",
        "        new_folder_name = str(number)\n",
        "        new_folder_path = os.path.join(folder_path, new_folder_name)\n",
        "\n",
        "        # Rename the folder\n",
        "        os.rename(os.path.join(folder_path, original_folder), new_folder_path)\n",
        "\n",
        "    return folder_mapping\n",
        "\n",
        "folder_path = 'ArASL_Database_54K_Final'\n",
        "\n",
        "# Create the folder mapping and rename folders\n",
        "mapping = rename_folders_and_create_mapping(folder_path)\n",
        "\n",
        "# Print the folder mapping\n",
        "print(\"Folder Mapping:\")\n",
        "print(mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sjyA1C1E5ik",
        "outputId": "64e1d361-49d3-469e-8d85-30e2277df5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder Mapping:\n",
            "{'dal': 0, 'ain': 1, 'yaa': 2, 'la': 3, 'jeem': 4, 'thal': 5, 'khaa': 6, 'meem': 7, 'zay': 8, 'thaa': 9, 'haa': 10, 'laam': 11, 'sheen': 12, 'waw': 13, 'bb': 14, 'fa': 15, 'dha': 16, 'ta': 17, 'taa': 18, 'gaaf': 19, 'nun': 20, 'kaaf': 21, 'ghain': 22, 'aleff': 23, 'ra': 24, 'seen': 25, 'toot': 26, 'dhad': 27, 'ya': 28, 'ha': 29, 'saad': 30, 'al': 31}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_folder, transform=None, target_size=(28, 28)):\n",
        "        self.root_folder = root_folder\n",
        "        self.transform = transform\n",
        "        self.target_size = target_size\n",
        "\n",
        "        # Get the list of image files\n",
        "        self.image_files = []\n",
        "        self.image_labels = []\n",
        "\n",
        "        for root, dirs, files in os.walk(root_folder):\n",
        "            for file in files:\n",
        "                if file.lower().endswith('.jpg'):\n",
        "                    self.image_files.append(os.path.join(root, file))\n",
        "                    self.image_labels.append(int(os.path.basename(root)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        label = self.image_labels[idx]\n",
        "\n",
        "        # Convert label to tensor\n",
        "        # print(\"Label\", label, type(label))\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        # Open the image\n",
        "        with Image.open(img_path) as img:\n",
        "            # Convert the image to grayscale\n",
        "            img = img.convert('L')\n",
        "\n",
        "            # Resize the image\n",
        "            img = img.resize(self.target_size)\n",
        "\n",
        "            # Apply additional transformations if specified\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            return (img, label)\n",
        "\n",
        "# Define the root folder and output folder\n",
        "root_folder_path = 'ArASL_Database_54K_Final'\n",
        "\n",
        "\n",
        "# Define transformations (resize to 28x28 and convert to tensor)\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((48, 48)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create an instance of the custom dataset\n",
        "custom_dataset = CustomDataset(root_folder_path, transform=data_transform)\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Define the size of the training and validation sets\n",
        "total_size = len(custom_dataset)\n",
        "train_size = int(0.8 * total_size)  # 80% for training\n",
        "val_size = total_size - train_size  # 20% for validation\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n",
        "\n",
        "mapping = {v:k for k,v in mapping.items()}"
      ],
      "metadata": {
        "id": "Efxefg5j94pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the data"
      ],
      "metadata": {
        "id": "ObDvaInfAdBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here is the mapping for each class and its encoding. In addition to the train_dataset and val_dataset"
      ],
      "metadata": {
        "id": "GmA6buxlh9XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset # Contains the training ArASL_Database_54K_Final dataset (80%)\n",
        "\n",
        "val_dataset  # Contains the validating ArASL_Database_54K_Final dataset (20%)\n",
        "\n",
        "\n",
        "print(\"The mapping between the letters and the encoding: \\n\", mapping)\n",
        "\n",
        "# Check the lengths of train_dataset and val_dataset.\n",
        "^?????\n",
        "^?????"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "60ugrf0DMF2N",
        "outputId": "34cf658b-d0b7-4f08-9568-1680b44d4a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-8-21dd4bbdc38d>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-21dd4bbdc38d>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    ^?????\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64 # To group each k samples together.\n",
        "\n",
        "# DataLoaders simplify the job of grouping the samples into batches.\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # no need to shuffle validation data"
      ],
      "metadata": {
        "id": "Oj4XUGKBQmwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's visualize an image."
      ],
      "metadata": {
        "id": "4bw5HNZeQ7Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_img_idx = 30 # Write any random index (between 0 and 59999)\n",
        "\n",
        "image = train_dataset[random_img_idx][0]  # 0 for image part in (image, label) tuple.\n",
        "label = train_dataset[random_img_idx][1]  # 1 for label part\n",
        "\n",
        "print(\"The image label:\", label.item(), mapping[label.item()])\n",
        "\n",
        "plt.imshow(image.reshape(image.shape[1], image.shape[1]), cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "kXxCJ5pQQ5jw",
        "outputId": "2773746d-2886-444e-ee32-0090eb953309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image label: 27 dhad\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79b734771150>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a loop to show 10 different images ranodmly"
      ],
      "metadata": {
        "id": "5wATuG1cPwms"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SIHE3pWlPvvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a NN uisng Pytorch. Then, train the model. Play with the layers to get the best model on the validation data, try to reach a 90% accuracy. At least, make 3 different layers. Also, try different activation functions."
      ],
      "metadata": {
        "id": "qvysz1ZnSh7f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5G7ib-G0LTC1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}